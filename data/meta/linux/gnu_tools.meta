a:2:{s:7:"current";a:8:{s:4:"date";a:2:{s:7:"created";i:1488294172;s:8:"modified";i:1489410114;}s:4:"user";s:0:"";s:7:"creator";s:0:"";s:11:"last_change";a:8:{s:4:"date";i:1505987678;s:2:"ip";s:14:"150.130.96.129";s:4:"type";s:1:"e";s:2:"id";s:15:"linux:gnu_tools";s:4:"user";s:6:"tadone";s:3:"sum";s:0:"";s:5:"extra";s:0:"";s:10:"sizechange";i:333;}s:5:"title";s:3:"AWK";s:8:"relation";a:2:{s:10:"references";a:4:{s:10:"linux:find";b:1;s:9:"linux:sed";b:1;s:10:"linux:nmap";b:1;s:11:"linux:xargs";b:1;}s:10:"firstimage";s:0:"";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:11:"description";a:1:{s:8:"abstract";s:503:"AWK

Print only 2 position with default delimiter


cURL

Download site/file (without saving) and grep its content:

Uppercase -O saves based on filename (will save as gettext.html):



-print0

Print  the  full file name on the standard output, followed by a null character (instead of the newline character that -print uses).  This allows file names that contain  newlines  or  other types  of  white space to be correctly interpreted by programs that process the find output. This option corresponâ€¦";}}s:10:"persistent";a:4:{s:4:"date";a:2:{s:7:"created";i:1488294172;s:8:"modified";i:1489410114;}s:4:"user";s:0:"";s:7:"creator";s:0:"";s:11:"last_change";a:8:{s:4:"date";i:1505987678;s:2:"ip";s:14:"150.130.96.129";s:4:"type";s:1:"e";s:2:"id";s:15:"linux:gnu_tools";s:4:"user";s:6:"tadone";s:3:"sum";s:0:"";s:5:"extra";s:0:"";s:10:"sizechange";i:333;}}}